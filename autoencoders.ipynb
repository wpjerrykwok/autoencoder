{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "To store a set of images using a minimal amount of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "Obtained from Arabic Handwritten Digits Dataset | Kaggle (https://www.kaggle.com/datasets/mloey1/ahdd1), original source unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "You are working with a team that is developing a mobile app for doing arithmetic by hand, in Arabic. The app will recognize digits in the user's handwriting as part of its functionality. In order to use a minimum amount of data, your job as a developer is to store each hand-drawn digit using as little memory as possible. Using a dataset of hand drawn Arabic digits, you will train an autoencoder to encode and decode these images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arabic Digits\n",
    "Arabic digits correspond to Roman digits according to the table below (N.Das, A. Mollah, S. Saha, S. Haque, 2010, https://arxiv.org/abs/1003.1891):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow libraries\n",
    "from tensorflow.keras.layers import Input, Reshape, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. Each row of *csvImages 10k x 784.csv* contains the gray scale values of a 28 x 28 image. Load this data into a pandas dataframe. Convert the dataframe to a numpy array using *pandas.values*. Print the shape of the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "digit_df = pd.read_csv('csvImages 10k x 784.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataframe to numpy array\n",
    "digits = digit_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print shape of data\n",
    "digits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "1. There are 9999 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Normalize by dividing each value by 255. In order to display the images, reshape the array so each image is 28 x 28 using *numpy.ndarray.reshape*. Use *matplotlib.plot.imshow* and *matplotlib.plot.subplot* to give a plot of the first five images using the 'gray' colour map. In order to put the data back in the original shape for input to the neural network, reshape each image to be 784 (one-dimensional).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print data type\n",
    "digits.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data by dividing by 255. and convert to float32\n",
    "digits = digits.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data for visualization\n",
    "digits = digits.reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display first 5 images\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(5):\n",
    "    # Plot the original images\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(digits[i], cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data for autoencoder\n",
    "digits = digits.reshape(-1, 28**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. Use *keras.layers* to create an input layer that matches the dimensions of your data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display dimensions of data\n",
    "digits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the input layer that matches the dimension of the data\n",
    "input_layer = Input(shape=(784,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Use *keras.layers* to create an encoding stage that has at least two layers and reduces the size of the data to 50% or less (less is better). You will need to choose activation functions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the encoding stage\n",
    "m1_enc1 = Reshape((28, 28, 1))(input_layer)\n",
    "m1_enc2 = Conv2D(8, (3, 3), activation='relu', padding='same')(m1_enc1)\n",
    "m1_enc3 = MaxPooling2D((2, 2), padding='same')(m1_enc2)\n",
    "m1_enc4 = Conv2D(8, (3, 3), activation='relu', padding='same')(m1_enc3)\n",
    "m1_enc5 = MaxPooling2D((2, 2), padding='same')(m1_enc4)\n",
    "m1_enc6 = Flatten()(m1_enc5)\n",
    "m1_enc7 = Dense(49, activation='relu')(m1_enc6)\n",
    "m1_encoder = Dense(9, activation='relu')(m1_enc7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "1. Since the project is working on images, we may use convolutional neural networks in the autoencoder.\n",
    "2. A multi-layer encoding stage is used.  \n",
    "3. First we use *Reshape* to fit *Conv2D* input dimensions. Then, *Conv2D* with 8 filters of size 3 by 3 is used with a RuLU *activation* function, *padding* as *same* to maintain the shape of the input and the output.\n",
    "4. *MaxPooling2D* is used to pool the information.\n",
    "5. The *Conv2D* and the *MaxPooling2D* repeat one more time.\n",
    "6. The *Flatten* layer is used to prepare for the *Dense* layer\n",
    "7. The first Dense layer is 49 units.\n",
    "8. The targeted encoder layer is of 9 units.\n",
    "9. The overall reduction in size is 1-9/784 = 98.85%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. Use *keras.layers* to create a decoding stage that has at least two layers and restores the data to its original size. You will need to choose activation functions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the decoding stage\n",
    "m1_dec1 = Dense(49, activation='relu')(m1_encoder)\n",
    "m1_dec2 = Dense(392, activation='relu')(m1_dec1)\n",
    "m1_dec3 = Reshape((7, 7, 8))(m1_dec2)\n",
    "m1_dec4 = Conv2D(8, (3, 3), activation='relu', padding='same')(m1_dec3)\n",
    "m1_dec5 = UpSampling2D((2, 2))(m1_dec4)\n",
    "m1_dec6 = Conv2D(8, (3, 3), activation='relu', padding='same')(m1_dec5)\n",
    "m1_dec7 = UpSampling2D((2, 2))(m1_dec6)\n",
    "m1_dec8 = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(m1_dec7)\n",
    "m1_decoder = Reshape((784,))(m1_dec8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "1. A multi-layer decoding stage is used. The layers are in the reverse of those in encoding stage. We use *UpSampling2D* to restore the pooled information.\n",
    "2. A RuLU activation function is used except the last decoder layer.\n",
    "3. The *sigmoid* activation function is used because the input values to the network are only between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d. Compile the complete autoencoder network. You will need to choose a loss function and an optimizer. Train the autoencoder using the image data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 8)         80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 392)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 49)                19257     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 450       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 49)                490       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 392)               19600     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 28, 28, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 1)         73        \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 784)               0         \n",
      "=================================================================\n",
      "Total params: 41,702\n",
      "Trainable params: 41,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# construct the autoencoder model by passing the first and last layers\n",
    "autoencoder_1 = Model(input_layer, m1_decoder)\n",
    "\n",
    "# print the summary\n",
    "autoencoder_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2707\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.1623\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.1338\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 5s 18ms/step - loss: 0.1231\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1173\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.1133\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1104\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.1082\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1064\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.1050\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.1039\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1028\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1019\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.1011\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.1004\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.1000\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0992\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0986\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0981\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0976\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0971\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0967\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0963\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.0961\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.0956\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 5s 18ms/step - loss: 0.0954\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 5s 18ms/step - loss: 0.0952\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0948\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0947\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0942\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0941\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 5s 18ms/step - loss: 0.0938\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0936\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0936\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0933\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0930\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0930\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0929\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0926\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0923\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0922\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0921\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0918\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0918\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.0916\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 6s 21ms/step - loss: 0.0915\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.0915\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.0914\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.0911\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.0910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x205d79f5a90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the autoencoder model\n",
    "autoencoder_1.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# train the autoencoder model\n",
    "autoencoder_1.fit(digits, digits, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "1. The *binary_crossentropy* is used as the loss function.\n",
    "2. The *adam* is used as the optimizer.\n",
    "3. The images are passed as the input and also as the desired output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e. Compile an encoder network from your trained input layer and encoding stage.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the encoder using input layer and encoding layer\n",
    "encoder_1 = Model(input_layer, m1_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. Use *matplotlib.plot.imshow* and *matplotlib.plot.subplot* and your trained models to give a plot of the first five original images along the top row, the encoded versions of those same images along the second row, and the decoded versions along the bottom row.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# obtain the original of the first 5 images\n",
    "original = digits[:5]\n",
    "\n",
    "# reshape the original images for visualization\n",
    "original_1_vis = original.reshape(-1, 28, 28)\n",
    "\n",
    "# obtain the encoder output of the first 5 images\n",
    "encoder_1_output = encoder_1.predict(original)\n",
    "\n",
    "# reshape the encoder output for visualization\n",
    "enc_1_output_vis = encoder_1_output.reshape(-1, 3, 3) * 255\n",
    "\n",
    "# obtain the decoder output of the first 5 images\n",
    "decoder_1_output = autoencoder_1.predict(original)\n",
    "\n",
    "# reshape the decoder output for visualization\n",
    "dec_1_output_vis = decoder_1_output.reshape(-1, 28, 28) * 255\n",
    "\n",
    "# Plot the original image, the encoder output, and the decoder output:\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "for i in range(5):\n",
    "    # Plot original images\n",
    "    plt.subplot(3, 5, i + 1)\n",
    "    plt.imshow(original_1_vis[i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    # Plot encoder output\n",
    "    plt.subplot(3, 5, i + 6)\n",
    "    plt.imshow(enc_1_output_vis[i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    # Plot decoder output\n",
    "    plt.subplot(3, 5, i + 11)\n",
    "    plt.imshow(dec_1_output_vis[i], cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "1. The decoded images cannot represent the original images satisfactorily.\n",
    "2. The third and fourth are bad with the strokes spread very wide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Return to question 2 and adjust the hyperparameters of your model until you are able to produce decoded images that represent the original images, with an encoding that uses as little data as possible; make a record of the adjustments you try in markdown.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "1. The number of filters is changed to 16 for the *Conv2D* layers. The number of neurons in the last *Dense* layer is updated accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 49)                38465     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 9)                 450       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 49)                490       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 784)               39200     \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 7, 7, 16)          2320      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 1)         145       \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 784)               0         \n",
      "=================================================================\n",
      "Total params: 85,870\n",
      "Trainable params: 85,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the encoding stage\n",
    "m2_enc1 = Reshape((28, 28, 1))(input_layer)\n",
    "m2_enc2 = Conv2D(16, (3, 3), activation='relu', padding='same')(m2_enc1)\n",
    "m2_enc3 = MaxPooling2D((2, 2), padding='same')(m2_enc2)\n",
    "m2_enc4 = Conv2D(16, (3, 3), activation='relu', padding='same')(m2_enc3)\n",
    "m2_enc5 = MaxPooling2D((2, 2), padding='same')(m2_enc4)\n",
    "m2_enc6 = Flatten()(m2_enc5)\n",
    "m2_enc7 = Dense(49, activation='relu')(m2_enc6)\n",
    "m2_encoder = Dense(9, activation='relu')(m2_enc7)\n",
    "\n",
    "# create the decoding stage\n",
    "m2_dec1 = Dense(49, activation='relu')(m2_encoder)\n",
    "m2_dec2 = Dense(784, activation='relu')(m2_dec1)\n",
    "m2_dec3 = Reshape((7, 7, 16))(m2_dec2)\n",
    "m2_dec4 = Conv2D(16, (3, 3), activation='relu', padding='same')(m2_dec3)\n",
    "m2_dec5 = UpSampling2D((2, 2))(m2_dec4)\n",
    "m2_dec6 = Conv2D(16, (3, 3), activation='relu', padding='same')(m2_dec5)\n",
    "m2_dec7 = UpSampling2D((2, 2))(m2_dec6)\n",
    "m2_dec8 = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(m2_dec7)\n",
    "m2_decoder = Reshape((784,))(m2_dec8)\n",
    "\n",
    "# construct the autoencoder model\n",
    "autoencoder_2 = Model(input_layer, m2_decoder)\n",
    "\n",
    "# print the summary\n",
    "autoencoder_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.2393\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.1427\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.1242\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.1166\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 9s 27ms/step - loss: 0.1115\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.1079\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.1055\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.1033\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.1018\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.1005\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.0994\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.0983\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.0974\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.0965\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.0957\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.0951\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.0943\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.0937\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.0926\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 8s 27ms/step - loss: 0.0920\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.0911\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.0907\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.0902\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.0896\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.0891\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.0887\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.0882\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.0880\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.0876\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.0872\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.0869\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.0869\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.0865\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.0860\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.0861\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.0858\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.0857\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.0855\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.0851\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 8s 27ms/step - loss: 0.0850\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.0849\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.0847\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.0845\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.0844\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.0841\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.0841\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.0841\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.0838\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.0836\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.0835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x205da5d48e0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the autoencoder model\n",
    "autoencoder_2.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# train the autoencoder model\n",
    "autoencoder_2.fit(digits, digits, epochs=50, batch_size=32, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the encoder using input layer and encoding layer\n",
    "encoder_2 = Model(input_layer, m2_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# obtain the original of the first 5 images\n",
    "original = digits[:5]\n",
    "\n",
    "# reshape the original images for visualization\n",
    "original_vis = original.reshape(-1, 28, 28)\n",
    "\n",
    "# obtain the encoder output of the first 5 images\n",
    "encoder_2_output = encoder_2.predict(original)\n",
    "\n",
    "# reshape the encoder output for visualization\n",
    "enc_2_output_vis = encoder_2_output.reshape(-1, 3, 3) * 255\n",
    "\n",
    "# obtain the decoder output of the first 5 images\n",
    "decoder_2_output = autoencoder_2.predict(original)\n",
    "\n",
    "# reshape the decoder output for visualization\n",
    "dec_2_output_vis = decoder_2_output.reshape(-1, 28, 28) * 255\n",
    "\n",
    "# Plot the original image, the encoder output, and the decoder output:\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "for i in range(5):\n",
    "    # Plot original images\n",
    "    plt.subplot(3, 5, i + 1)\n",
    "    plt.imshow(original_vis[i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    # Plot encoder output\n",
    "    plt.subplot(3, 5, i + 6)\n",
    "    plt.imshow(enc_2_output_vis[i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    # Plot decoder output\n",
    "    plt.subplot(3, 5, i + 11)\n",
    "    plt.imshow(dec_2_output_vis[i], cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "1. The decoded images cannot represent the original images satsifactorily.\n",
    "2. Both third and fourth images are slightly improved but the strokes are not sharp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "1. The number of filters is changed to 80 and 64 for the *Conv2D* layers. The number of neurons in the last *Dense* layer is updated accordingly.\n",
    "2. The number of neurons in the *Dense* layers before and after the last encoding stage is also changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 80)        800       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 80)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 64)        46144     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 81)                254097    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 9)                 738       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 81)                810       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3136)              257152    \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 80)        46160     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 28, 28, 80)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 28, 28, 1)         721       \n",
      "_________________________________________________________________\n",
      "reshape_8 (Reshape)          (None, 784)               0         \n",
      "=================================================================\n",
      "Total params: 643,550\n",
      "Trainable params: 643,550\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the encoding stage\n",
    "m3_enc1 = Reshape((28, 28, 1))(input_layer)\n",
    "m3_enc2 = Conv2D(80, (3, 3), activation='relu', padding='same')(m3_enc1)\n",
    "m3_enc3 = MaxPooling2D((2, 2), padding='same')(m3_enc2)\n",
    "m3_enc4 = Conv2D(64, (3, 3), activation='relu', padding='same')(m3_enc3)\n",
    "m3_enc5 = MaxPooling2D((2, 2), padding='same')(m3_enc4)\n",
    "m3_enc6 = Flatten()(m3_enc5)\n",
    "m3_enc7 = Dense(81, activation='relu')(m3_enc6)\n",
    "m3_encoder = Dense(9, activation='relu')(m3_enc7)\n",
    "\n",
    "# create the decoding stage\n",
    "m3_dec1 = Dense(81, activation='relu')(m3_encoder)\n",
    "m3_dec2 = Dense(3136, activation='relu')(m3_dec1)\n",
    "m3_dec3 = Reshape((7, 7, 64))(m3_dec2)\n",
    "m3_dec4 = Conv2D(64, (3, 3), activation='relu', padding='same')(m3_dec3)\n",
    "m3_dec5 = UpSampling2D((2, 2))(m3_dec4)\n",
    "m3_dec6 = Conv2D(80, (3, 3), activation='relu', padding='same')(m3_dec5)\n",
    "m3_dec7 = UpSampling2D((2, 2))(m3_dec6)\n",
    "m3_dec8 = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(m3_dec7)\n",
    "m3_decoder = Reshape((784,))(m3_dec8)\n",
    "\n",
    "# construct the autoencoder model\n",
    "autoencoder_3 = Model(input_layer, m3_decoder)\n",
    "\n",
    "# print the summary\n",
    "autoencoder_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 0.2034\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 0.1265\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 0.1148\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 0.1091\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 0.1052\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 0.1021\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 0.0998\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 31s 100ms/step - loss: 0.0984\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 0.0968\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 0.0960\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 0.0950\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 31s 100ms/step - loss: 0.0939\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 31s 99ms/step - loss: 0.0931\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 0.0924\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 0.0916\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 0.0911\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 0.0904\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 0.0901\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 0.0896\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 0.0889\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 0.0885\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 0.0879\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 0.0877\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 0.0873\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 0.0867\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 0.0865\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 0.0860\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 0.0858\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 0.0854\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 0.0851\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 0.0847\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 0.0844\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 30s 95ms/step - loss: 0.0843\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 0.0838\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 0.0837\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 30s 97ms/step - loss: 0.0836\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 30s 94ms/step - loss: 0.0833\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 32s 103ms/step - loss: 0.0828\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 38s 120ms/step - loss: 0.0828\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 38s 121ms/step - loss: 0.0824\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 39s 125ms/step - loss: 0.0825\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.0821\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 0.0819\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 37s 119ms/step - loss: 0.0815\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 0.0814\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.0813\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 0.0812\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 37s 118ms/step - loss: 0.0807\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.0807\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.0807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x205d762bc10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the autoencoder model\n",
    "autoencoder_3.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# train the autoencoder model\n",
    "autoencoder_3.fit(digits, digits, epochs=50, batch_size=32, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the encoder using input layer and encoding layer\n",
    "encoder_3 = Model(input_layer, m3_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000205D9BF6CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000205D75A03A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# obtain the original of the first 5 images\n",
    "original = digits[:5]\n",
    "\n",
    "# reshape the original images for visualization\n",
    "original_vis = original.reshape(-1, 28, 28)\n",
    "\n",
    "# obtain the encoder output of the first 5 images\n",
    "encoder_3_output = encoder_3.predict(original)\n",
    "\n",
    "# reshape the encoder output for visualization\n",
    "enc_3_output_vis = encoder_3_output.reshape(-1, 3, 3) * 255\n",
    "\n",
    "# obtain the decoder output of the first 5 images\n",
    "decoder_3_output = autoencoder_3.predict(original)\n",
    "\n",
    "# reshape the decoder output for visualization\n",
    "dec_3_output_vis = decoder_3_output.reshape(-1, 28, 28) * 255\n",
    "\n",
    "# Plot the original image, the encoder output, and the decoder output:\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "for i in range(5):\n",
    "    # Plot original images\n",
    "    plt.subplot(3, 5, i + 1)\n",
    "    plt.imshow(original_vis[i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    # Plot encoder output\n",
    "    plt.subplot(3, 5, i + 6)\n",
    "    plt.imshow(enc_3_output_vis[i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    # Plot decoder output\n",
    "    plt.subplot(3, 5, i + 11)\n",
    "    plt.imshow(dec_3_output_vis[i], cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "1. The decoded images can represent the original images satisfactorily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Use markdown to describe how well the autoencoder is working, making reference to the plots.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "1. The autoencoder is working very nicely.\n",
    "2. The first decoded image looks almost the same as the original image.\n",
    "3. The second decoded image looks almost the same as the original image. The curve and the straight strokes are resembled very nicely.  \n",
    "4. The third decoded image looks very much like the original image. The shape of the two strokes are restored very nicely. The only problem is intersection point of the two strokes. That intersection point should be more solid.\n",
    "5. The fourth decoded image looks very much like the original image. The shape is very well maintained. The only problem is the end of the strokes is smoothened. We lost some details there.\n",
    "6. The fifth decoded image looks very much like the original image. The shape is very well maintained. The problem area is the connection point. In the original image, the circle is not complete. We again lost some details at the start and end points of the stroke.\n",
    "7. Overall, the autoencoder has nicely restored the original images. The shapes are well maintained and the strokes do not spread out. However, the common problem observed from the plots is that the details in the start and end of a stroke is usually being smoothened and lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. State the amount of data needed to store a single image, considering that a floating-point number is 4 bytes of data. Calculate how much memory will be saved as a percentage.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the floating point number memory size\n",
    "floating_mem_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory size of the original image: 3136 bytes\n"
     ]
    }
   ],
   "source": [
    "# define the number of original pixels\n",
    "original_pixels = digits[0].shape[0]\n",
    "# print the memory size of the original image\n",
    "print('Memory size of the original image: {} bytes'.format(original_pixels * floating_mem_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory size of the encoder output: 36 bytes\n"
     ]
    }
   ],
   "source": [
    "# define the number of encoder output pixels\n",
    "encoder_output_pixels = encoder_1_output[0].shape[0]\n",
    "# print the memory size of the encoder output\n",
    "print('Memory size of the encoder output: {} bytes'.format(encoder_output_pixels * floating_mem_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory saved: 98.85204081632652%\n"
     ]
    }
   ],
   "source": [
    "# print the memory saved as a percentage\n",
    "print('Memory saved: {}%'.format((1 - (encoder_output_pixels / original_pixels)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "1. Each pixel is one floating-point number, 4 bytes.\n",
    "2. The original image is 28 * 28 or 784 pixels in gray scale value. To store the original image, 784 * 4 = 3136 bytes.\n",
    "3. The encoded image is 3 * 3 or 9 pixels in gray scale value. To store the encoded image, 9 * 4 = 36 bytes.\n",
    "4. Memory saved as a percentage is 98.85%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
